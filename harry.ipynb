{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b1470f-66ea-4ff8-b324-6ed43aa3c89a",
   "metadata": {},
   "source": [
    "# Langchain e GenAI: O mínimo (e tudo) o que você precisa saber sobre essa modinha e como isso afeta a infraestrutura e devops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99704d9-72d3-4a39-9c05-748f6c2b995a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.332-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-3.17.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting pgvector\n",
      "  Using cached pgvector-0.2.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting text_generation\n",
      "  Using cached text_generation-0.6.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nb-mermaid\n",
      "  Using cached nb_mermaid-0.1.0-py3-none-any.whl\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.8/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting anyio<4.0 (from langchain)\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
      "  Downloading langsmith-0.0.62-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.8/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.3 in ./venv/lib/python3.8/site-packages (from pypdf) (4.8.0)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Using cached torch-2.1.0-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Using cached torchvision-0.16.0-cp38-cp38-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting IPython<4.0,>3.0 (from nb-mermaid)\n",
      "  Using cached ipython-3.2.3-py3-none-any.whl (3.4 MB)\n",
      "Collecting jupyter-pip (from nb-mermaid)\n",
      "  Using cached jupyter_pip-0.3.1-py3-none-any.whl\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from transformers) (23.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./venv/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.8/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.8/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in ./venv/lib/python3.8/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.4.0->sentence-transformers)\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting pytest-subtests<0.12.0,>=0.11.0 (from langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading pytest_subtests-0.11.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch>=1.6.0->sentence-transformers)\n",
      "  Using cached triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting click (from nltk->sentence-transformers)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->sentence-transformers)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence-transformers)\n",
      "  Using cached Pillow-10.1.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pytest>=7.0 (from pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading pytest-7.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting iniconfig (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting pluggy<2.0,>=0.12 (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain)\n",
      "  Downloading pluggy-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in ./venv/lib/python3.8/site-packages (from pytest>=7.0->pytest-subtests<0.12.0,>=0.11.0->langsmith<0.1.0,>=0.0.52->langchain) (2.0.1)\n",
      "Downloading langchain-0.0.332-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
      "Using cached pgvector-0.2.3-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached psycopg2_binary-2.9.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached text_generation-0.6.1-py3-none-any.whl (10 kB)\n",
      "Using cached transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "Using cached aiohttp-3.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.62-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m917.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Using cached pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "Using cached pydantic_core-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "Using cached safetensors-0.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached SQLAlchemy-2.0.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tokenizers-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Using cached torch-2.1.0-cp38-cp38-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "Using cached torchvision-0.16.0-cp38-cp38-manylinux1_x86_64.whl (6.9 MB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "Using cached greenlet-3.0.1-cp38-cp38-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (618 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached Pillow-10.1.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "Downloading pytest_subtests-0.11.0-py3-none-any.whl (6.7 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading pytest-7.4.3-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.1/325.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Downloading pluggy-1.3.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sentencepiece, mpmath, jupyter-pip, IPython, tqdm, threadpoolctl, tenacity, sympy, safetensors, regex, pypdf, pydantic-core, psycopg2-binary, pluggy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nb-mermaid, mypy-extensions, multidict, marshmallow, jsonpatch, joblib, iniconfig, greenlet, fsspec, frozenlist, filelock, click, async-timeout, anyio, annotated-types, yarl, typing-inspect, triton, SQLAlchemy, scipy, pytest, pydantic, pgvector, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, huggingface-hub, aiosignal, tokenizers, scikit-learn, pytest-subtests, nvidia-cusolver-cu12, dataclasses-json, aiohttp, transformers, torch, text_generation, langsmith, torchvision, langchain, sentence-transformers\n",
      "  Attempting uninstall: IPython\n",
      "    Found existing installation: ipython 8.12.3\n",
      "    Uninstalling ipython-8.12.3:\n",
      "      Successfully uninstalled ipython-8.12.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipykernel 6.26.0 requires ipython>=7.23.1, but you have ipython 3.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed IPython-3.2.3 SQLAlchemy-2.0.23 aiohttp-3.8.6 aiosignal-1.3.1 annotated-types-0.6.0 anyio-3.7.1 async-timeout-4.0.3 click-8.1.7 dataclasses-json-0.6.1 filelock-3.13.1 frozenlist-1.4.0 fsspec-2023.10.0 greenlet-3.0.1 huggingface-hub-0.17.3 iniconfig-2.0.0 joblib-1.3.2 jsonpatch-1.33 jupyter-pip-0.3.1 langchain-0.0.332 langsmith-0.0.62 marshmallow-3.20.1 mpmath-1.3.0 multidict-6.0.4 mypy-extensions-1.0.0 nb-mermaid-0.1.0 networkx-3.1 nltk-3.8.1 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 pgvector-0.2.3 pillow-10.1.0 pluggy-1.3.0 psycopg2-binary-2.9.9 pydantic-2.4.2 pydantic-core-2.10.1 pypdf-3.17.0 pytest-7.4.3 pytest-subtests-0.11.0 regex-2023.10.3 safetensors-0.4.0 scikit-learn-1.3.2 scipy-1.10.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tenacity-8.2.3 text_generation-0.6.1 threadpoolctl-3.2.0 tokenizers-0.14.1 torch-2.1.0 torchvision-0.16.0 tqdm-4.66.1 transformers-4.35.0 triton-2.1.0 typing-inspect-0.9.0 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain pypdf sentence-transformers pgvector psycopg2-binary text_generation nb-mermaid transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5da490-113e-4e27-902c-61f1eb710863",
   "metadata": {},
   "source": [
    "![title](persist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd259ad-6e00-4cd0-8779-83399e6fec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18769154-f994-4422-a693-0d51a2b012d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_documents = []\n",
    "\n",
    "text_document = 'harry.txt'\n",
    "loader = TextLoader(text_document)\n",
    "data = loader.load()\n",
    "langchain_documents.extend(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31818d84-bc50-44e6-b1e1-ce6626ed3cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Harry Potter and the Sorcerer's Stone\\n\\n\\nCHAPTER ONE\\n\\nTHE BOY WHO LIVED\\n\\nMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\\nthat they were perfectly normal, thank you very much. They were the last\\npeople you'd expect to be involved in anything strange or mysterious,\\nbecause they just didn't hold with such nonsense.\", metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='Mr. Dursley was the director of a firm called Grunnings, which made\\ndrills. He was a big, beefy man with hardly any neck, although he did\\nhave a very large mustache. Mrs. Dursley was thin and blonde and had\\nnearly twice the usual amount of neck, which came in very useful as she\\nspent so much of her time craning over garden fences, spying on the', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='neighbors. The Dursleys had a small son called Dudley and in their\\nopinion there was no finer boy anywhere.', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content=\"The Dursleys had everything they wanted, but they also had a secret, and\\ntheir greatest fear was that somebody would discover it. They didn't\\nthink they could bear it if anyone found out about the Potters. Mrs.\\nPotter was Mrs. Dursley's sister, but they hadn't met for several years;\\nin fact, Mrs. Dursley pretended she didn't have a sister, because her\", metadata={'source': 'harry.txt'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(langchain_documents)\n",
    "split_docs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159507bb-5718-48df-81e8-482df8e9cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/projs/talk/langchain/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-mpnet-base-v2', cache_folder=None, model_kwargs={'device': 'cuda'}, encode_kwargs={}, multi_process=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "hf = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba05892-12e1-432e-8212-0b5759d587cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:changeme@127.0.0.1:5432/\"\n",
    "CONNECTION_STRING2= \"dbname=postgres user=postgres password=changeme host=127.0.0.1\"\n",
    "# docker run --rm -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=changeme -p 5432:5432 ankane/pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5b0287-5399-4223-98db-b1780e851fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collection not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=hf,\n",
    "    documents=split_docs,\n",
    "    collection_name=\"data\",\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True,\n",
    "    engine_args=dict(        echo=False)\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55c9426-def6-48a9-92e7-ada25f222ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83605be1-9d8e-48cd-8bad-1e82b7f2e74c [0.04018502,0.037721794,-0.016705789,0.032354504,-0.009721482,0.027126 Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      " {'source': 'harry.txt'} 591a9dae-7e90-11ee-b3d4-e8fb1cf70881 e72a99ef-bc8a-4b62-800f-2fa4008401eb\n",
      "83605be1-9d8e-48cd-8bad-1e82b7f2e74c [0.021211743,0.019177407,0.007544621,0.021712935,-0.021291347,0.082268 Mr. Dursley was the director of a firm c {'source': 'harry.txt'} 591aabd2-7e90-11ee-b3d4-e8fb1cf70881 a2db591c-3670-4012-86d6-def6af57142b\n",
      "83605be1-9d8e-48cd-8bad-1e82b7f2e74c [0.021557348,0.04593239,-0.0025738447,-0.0013979004,-0.01920698,0.0316 neighbors. The Dursleys had a small son  {'source': 'harry.txt'} 591ab118-7e90-11ee-b3d4-e8fb1cf70881 2b181a25-4f20-489d-bf1c-f60cba3977a7\n",
      "83605be1-9d8e-48cd-8bad-1e82b7f2e74c [-0.013298681,0.028408222,-0.030839026,0.013962188,-0.010927177,0.0852 The Dursleys had everything they wanted, {'source': 'harry.txt'} 591ab424-7e90-11ee-b3d4-e8fb1cf70881 fedaf60f-cca0-45bb-bba2-f3d04343eae8\n",
      "83605be1-9d8e-48cd-8bad-1e82b7f2e74c [-0.021389738,0.054306984,-0.013483072,0.006095653,-0.012781362,0.0726 sister and her good-for-nothing husband  {'source': 'harry.txt'} 591ab6cc-7e90-11ee-b3d4-e8fb1cf70881 d4360c4f-1ebb-48b6-ba05-080408406448\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "v=[]\n",
    "with psycopg2.connect(CONNECTION_STRING2) as conn: \n",
    "   with conn.cursor() as cur:\n",
    "      cur.execute(\"select * from langchain_pg_embedding limit 5\")\n",
    "      v = cur.fetchall()\n",
    "for i in v:\n",
    "    print(i[0],i[1][:70],i[2][:40],i[3],i[4],i[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d7c26d-9ed6-4587-bb50-426682b68319",
   "metadata": {},
   "source": [
    "![title](query.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c2ebcd-9817-4801-99e2-ca062dce5916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\"My dear Professor, surely a sensible person like yourself can call him\\nby his name? All this \\'You- Know-Who\\' nonsense -- for eleven years I\\nhave been trying to persuade people to call him by his proper name:\\nVoldemort.\" Professor McGonagall flinched, but Dumbledore, who was\\nunsticking two lemon drops, seemed not to notice. \"It all gets so', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='\"I know you haven \\'t, said Professor McGonagall, sounding half\\nexasperated, half admiring. \"But you\\'re different. Everyone knows you\\'re\\nthe only one You-Know- oh, all right, Voldemort, was frightened of.\"\\n\\n\"You flatter me,\" said Dumbledore calmly. \"Voldemort had powers I will\\nnever have.\"\\n\\n\"Only because you\\'re too -- well -- noble to use them.\"', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='The Dursleys often spoke about Harry like this, as though he wasn\\'t\\nthere -- or rather, as though he was something very nasty that couldn\\'t\\nunderstand them, like a slug.\\n\\n\"What about what\\'s-her-name, your friend -- Yvonne?\"\\n\\n\"On vacation in Majorca,\" snapped Aunt Petunia.', metadata={'source': 'harry.txt'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(query=\"What nickname do Dumbledore and McGonagall use when discussing Voldemort \", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41b4ca3-1aff-4393-bbcf-050bd79acbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\"Hagrid,\" said Dumbledore, sounding relieved. \"At last. And where did\\nyou get that motorcycle?\"\\n\\n\"Borrowed it, Professor Dumbledore, sit,\" said the giant, climbing\\ncarefully off the motorcycle as he spoke. \"Young Sirius Black lent it to\\nme. I\\'ve got him, sir.\"\\n\\n\"No problems, were there?\"', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='Wiping his streaming eyes on his jacket sleeve, Hagrid swung himself\\nonto the motorcycle and kicked the engine into life; with a roar it rose\\ninto the air and off into the night.\\n\\n\"I shall see you soon, I expect, Professor McGonagall,\" said Dumbledore,\\nnodding to her. Professor McGonagall blew her nose in reply.', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='Passersby stared a lot at Hagrid as they walked through the little town\\nto the station. Harry couldn\\'t blame them. Not only was Hagrid twice as\\ntall as anyone else, he kept pointing at perfectly ordinary things like\\nparking meters and saying loudly, \"See that, Harry? Things these Muggles\\ndream up, eh?\"', metadata={'source': 'harry.txt'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(query=\"What kind of vehicle does Hagrid drive?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d9027a-d2a7-4971-b4c2-c08411759974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Harry put the plates of egg and bacon on the table, which was difficult\\nas there wasn\\'t much room. Dudley, meanwhile, was counting his presents.\\nHis face fell.\\n\\n\"Thirty-six,\" he said, looking up at his mother and father. \"That\\'s two\\nless than last year.\"\\n\\n\"Darling, you haven\\'t counted Auntie Marge\\'s present, see, it\\'s here\\nunder this big one from Mommy and Daddy.\"', metadata={'source': 'harry.txt'}),\n",
       " Document(page_content=\"When he was dressed he went down the hall into the kitchen. The table\\nwas almost hidden beneath all Dudley's birthday presents. It looked as\\nthough Dudley had gotten the new computer he wanted, not to mention the\\nsecond television and the racing bike. Exactly why Dudley wanted a\\nracing bike was a mystery to Harry, as Dudley was very fat and hated\", metadata={'source': 'harry.txt'}),\n",
       " Document(page_content='Aunt Petunia obviously scented danger, too, because she said quickly,\\n\"And we\\'ll buy you another two presents while we\\'re out today. How\\'s\\nthat, popkin? Two more presents. Is that all right\\'\\'\\n\\nDudley thought for a moment. It looked like hard work. Finally he said\\nslowly, \"So I\\'ll have thirty ... thirty...\"\\n\\n\"Thirty-nine, sweetums,\" said Aunt Petunia.', metadata={'source': 'harry.txt'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(query=\"How many presents does Dudley Dursley receive on his birthday, to his great distress?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2551ea89-e571-4df3-9c35-d45ace52dc48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"bigscience/bloom-1b7\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"max_length\": 377},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07fbf04-1c99-4649-a403-e7388ce3f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b35034-3447-4905-b00b-58cefe129eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A motorcycle.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"What kind of vehicle does Hagrid drive?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f70ebb-f63d-40e7-ae81-d82d4a76807c",
   "metadata": {},
   "source": [
    "![title](agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429dad72-f36a-4543-94af-d7512a6f05b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
